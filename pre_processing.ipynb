{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipImport(filenumber):\n",
    "    filestr = str(filenumber)\n",
    "    video = cv2.VideoCapture(\"clips/\"+filestr)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_number = 11\n",
    "cap = cv2.VideoCapture('clips/{}.mp4'.format(video_number))\n",
    " \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fourcc_noised = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('processed_clips/{}/processed_{}.mp4'.format(video_number, video_number),fourcc, 24, (512,512))\n",
    "out_noised = cv2.VideoWriter('processed_clips/{}/noised/processed_noised_{}.mp4'.format(video_number, video_number), fourcc_noised, 24, (512,512))\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cropped = frame[104:616, 384:896]\n",
    "        noised = noisy(\"gauss\", cropped)\n",
    "        noised = noised.astype(np.float32)\n",
    "        noised_gray = cv2.cvtColor(noised, cv2.COLOR_BGR2GRAY)\n",
    "        noised_gray = cv2.cvtColor(noised_gray,cv2.COLOR_GRAY2BGR)\n",
    "        cropped = cropped.astype(np.float32)\n",
    "        cropped_gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "        cropped_gray = cv2.cvtColor(cropped_gray, cv2.COLOR_GRAY2BGR)\n",
    "        #cropped_gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "        #cropped_gray = cv2.cvtColor(cropped_gray, cv2.COLOR_GRAY2BGR)\n",
    "        #noised_gray = noised_gray.astype(np.float64)\n",
    "        #a = cv2.resize(cropped,(512,512),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "        #b = cv2.resize(noised_gray,(512,512),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "        cv2.imwrite(\"processed_clips/{}/frame_{}\".format(video_number, i)+\".png\", cropped)\n",
    "        cv2.imwrite(\"processed_clips/{}/noised/noised_frame_{}\".format(video_number, i)+\".png\", noised_gray)\n",
    "        cv2.imwrite(\"processed_clips/{}/bw/bw_frame_{}\".format(video_number, i)+\".png\", cropped_gray)\n",
    "        #out.write(cropped)\n",
    "        #out_noised.write(noised_gray)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "    i += 1\n",
    "    \n",
    "files = glob.glob(\"processed_clips/{}/*.png\".format(video_number))\n",
    "files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "files_noised = glob.glob(\"processed_clips/{}/noised/*.png\".format(video_number))\n",
    "files_noised.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "for filename in files:\n",
    "    img = cv2.imread(filename)\n",
    "    out.write(img)\n",
    "    \n",
    "for noised_filename in files_noised:\n",
    "    img_noised = cv2.imread(noised_filename)\n",
    "    out_noised.write(img_noised)\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "out_noised.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_number = 1\n",
    "#cap = cv2.VideoCapture('clips/{}.mp4'.format(video_number))\n",
    " \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fourcc_noised = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('processed_clips/{}/processed_{}.mp4'.format(video_number, video_number),fourcc, 24, (512,512))\n",
    "out_noised = cv2.VideoWriter('processed_clips/{}/noised/processed_noised_{}.mp4'.format(video_number, video_number), fourcc_noised, 24, (512,512))\n",
    "\n",
    "\n",
    "files = glob.glob(\"processed_clips/{}/*.png\".format(video_number))\n",
    "files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "files_noised = glob.glob(\"processed_clips/{}/noised/*.png\".format(video_number))\n",
    "files_noised.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "for filename in files:\n",
    "    img = cv2.imread(filename)\n",
    "    out.write(img)\n",
    "    \n",
    "for noised_filename in files_noised:\n",
    "    img_noised = cv2.imread(noised_filename)\n",
    "    out_noised.write(img_noised)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "out.release()\n",
    "out_noised.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "out_noised.release()\n",
    "out2.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db964bef0e2f4e889dbf5ff18d702c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:877: error: (-215:Assertion failed) !image.empty() in function 'cv::imencode'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2d9160e63844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"processed_clips/0/noised/noised_frame{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mout2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdisplay_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mout2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:877: error: (-215:Assertion failed) !image.empty() in function 'cv::imencode'\n"
     ]
    }
   ],
   "source": [
    "disp = widgets.Image()\n",
    "display(disp)\n",
    "\n",
    "fourcc_noised = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out2 = cv2.VideoWriter('processed_clips/{}/noised/processed_noised_{}.mp4'.format(video_number, video_number), fourcc_noised, 24, (512,512))\n",
    "for i in range(269):\n",
    "    im = cv2.imread(\"processed_clips/0/noised/noised_frame{}\".format(i))\n",
    "    out2.write(im)\n",
    "    display_image = cv2.imencode('.png', im)[1].tostring()\n",
    "    disp.value = display_image\n",
    "out2.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clips/frames/frame_0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:661: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'cv::imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-e797937288a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mfilm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clips/3.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msplitFrames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-e797937288a2>\u001b[0m in \u001b[0;36msplitFrames\u001b[1;34m(video)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:661: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'cv::imwrite_'\n"
     ]
    }
   ],
   "source": [
    "def splitFrames(video):\n",
    "    ret, frame = video.read()\n",
    "    path = (\"clips/frames/frame_{}\")\n",
    "    counter = 0 \n",
    "    print(path.format(counter))\n",
    "    while ret:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(path.format(counter), frame)\n",
    "        counter += 1\n",
    "    video.release()\n",
    "    \n",
    "film1 = cv2.VideoCapture(\"clips/3.mp4\")\n",
    "splitFrames(film1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_0': <VideoCapture 0000019CC34EC4F0>, 'video_1': <VideoCapture 0000019CC34EC2D0>, 'video_2': <VideoCapture 0000019CC34EC0B0>, 'video_3': <VideoCapture 0000019CC34EC350>, 'video_4': <VideoCapture 0000019CC34EC3D0>, 'video_5': <VideoCapture 0000019CC34EC070>, 'video_6': <VideoCapture 0000019CC34EC250>, 'video_7': <VideoCapture 0000019CC34EC450>, 'video_8': <VideoCapture 0000019CC59F28D0>, 'video_9': <VideoCapture 0000019CC59F2870>, 'video_10': <VideoCapture 0000019CC59F25F0>, 'video_11': <VideoCapture 0000019CC59F27D0>, 'video_12': <VideoCapture 0000019CC59F2730>, 'video_13': <VideoCapture 0000019CC59F2670>, 'video_14': <VideoCapture 0000019CC59F26D0>, 'video_15': <VideoCapture 0000019CC59F2690>, 'video_16': <VideoCapture 0000019CC59F2550>, 'video_17': <VideoCapture 0000019CC7212DF0>, 'video_18': <VideoCapture 0000019CC7212930>, 'video_19': <VideoCapture 0000019CC72122F0>, 'video_20': <VideoCapture 0000019CC7212690>, 'video_21': <VideoCapture 0000019CC72129B0>, 'video_22': <VideoCapture 0000019CC7212E30>, 'video_23': <VideoCapture 0000019CC7212D50>}\n"
     ]
    }
   ],
   "source": [
    "videoDict = {}\n",
    "for i in range(24):\n",
    "    videoDict[\"video_{0}\".format(i)] = clipImport(i)\n",
    "    splitFrames(videoDict[\"video_{0}\".format(i)])\n",
    "print(videoDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7712107fee7442b6a0d553dd4da487b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'video_reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-451425deff42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdisplay_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mvideo_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m#splitFrames(film)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video_reader' is not defined"
     ]
    }
   ],
   "source": [
    "film = cv2.VideoCapture(\"clips/2.mp4\")\n",
    "disp = widgets.Image()\n",
    "display(disp)\n",
    "\n",
    "ret, frame = film.read()\n",
    "while ret:\n",
    "    ret, frame = film.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    display_image = cv2.imencode('.png', frame)[1].tostring()\n",
    "    disp.value = display_image\n",
    "film.release()\n",
    "#splitFrames(film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = 30\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "                  for i in image.shape]\n",
    "        out[coords] = 1\n",
    "\n",
    "      # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "                  for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "processed_clips/1/frame_0.png\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "output_filename = \"processed_clips/1/processed_1.mp4\"\n",
    "noised_output_filename = \"processed_clips/1/noised_1.mp4\"\n",
    "backend = cv2.CAP_ANY\n",
    "fourcc_code = cv2.VideoWriter_fourcc(*\"VP80\")\n",
    "fps = 24\n",
    "frame_size = (512, 512)\n",
    "output_video = cv2.VideoWriter(output_filename, backend, fourcc_code, fps, frame_size)\n",
    "noised_output_video = cv2.VideoWriter(noised_output_filename, backend, fourcc_code, fps, frame_size)\n",
    "\n",
    "input_video = cv2.VideoCapture(\"clips/1.mp4\")\n",
    "ret, frame = input_video.read()\n",
    "path = \"processed_clips/1/frame_{}.png\"\n",
    "print(type(frame))\n",
    "counter = 0\n",
    "print(path.format(counter))\n",
    "while ret:\n",
    "    ret, frame = input_video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    cropped = frame[104:616, 384:896]\n",
    "    #location = path.format(counter)\n",
    "    cv2.imwrite(path.format(counter), cropped)\n",
    "    output_video.write(cropped)\n",
    "    counter += 1\n",
    "print(type(cropped))\n",
    "input_video.release()\n",
    "output_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cwiks\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\cwiks\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-0dcb6355b141>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#widgets.Image(value=display_image3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#widgets.Image(value=display_image4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplay_image4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#widgets.Image(value=garyImage)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'mat'"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"processed_clips/0/frame_0.png\")\n",
    "noised_image1 = noisy(\"gauss\", image)\n",
    "noised_image2 = noisy(\"s&p\", noised_image1)\n",
    "noised_image3 = noisy(\"poisson\", noised_image2)\n",
    "noised_image4 = noisy(\"speckle\", image)\n",
    "#grayImage = cv2.cvtColor(noised_image4, cv2.COLOR_BGR2GRAY)\n",
    "display_image1 = cv2.imencode('.png', image)[1].tostring()\n",
    "display_image2 = cv2.imencode('.png', noised_image1)[1].tostring()\n",
    "display_image3 = cv2.imencode('.png', noised_image2)[1].tostring()\n",
    "display_image4 = cv2.imencode('.png', noised_image3)[1].tostring()\n",
    "#display_image5 = cv2.imencode('.png', grayImage)[1].tostring()\n",
    "#widgets.Image(value=display_image1)\n",
    "#widgets.Image(value=display_image2)\n",
    "#widgets.Image(value=display_image3)\n",
    "#widgets.Image(value=display_image4)\n",
    "cv2.imshow('image',display_image4)\n",
    "\n",
    "#widgets.Image(value=garyImage)\n",
    "#cv2.imwrite(\"processed_clips/0/noised/noised_frame_0.png\", display_image5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_each_frame(path, no_of_frames):\n",
    "    for i in range(no_of_frames):\n",
    "        image = cv2.imread(path + \"frame_{}\".format(i) + \".png\")\n",
    "        print(path + \"frame_{}\".format(i) + \".png\")\n",
    "        noised = noisy(\"speckle\", image)\n",
    "        cv2.imwrite(\".png\", path + \"noised/noised_frame{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c34f6d0f8c44c3696ff5a9714a471ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x08\\x02\\x00\\x00\\x00{\\x1aC\\xaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = cv2.imread(\"processed_clips/2/frame_0.png\")\n",
    "noised = noisy(\"gauss\", image)\n",
    "display_image1 = cv2.imencode('.png', noised)[1].tostring()\n",
    "cv2.imshow(\"image\", noised)\n",
    "widgets.Image(value=display_image1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
